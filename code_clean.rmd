---
title: "code for Comp Gen final project"
output: md_document
---

---
title: "Comp Gen Project"
csl: plos.csl
output:
  github_document: default
bibliography: Bib.bib
---
# A few things to note:  
* You should be able to 'Run All' of this R code in this document.  
* Some of the code runs on sample data, out of necessity - many of the input files will not in my repo. But this results in some of the output graphs looking really weird.  
* Code that is not written in R can be found in the `code` folder, or where otherwise indicated.  
* In the README there were certain code chunks that I broke up into smaller chunks to make my descriptions more clear. 


# Load Libraries
```{r setup, include=FALSE}
knitr::opts_chunk$set(
	message = FALSE,
	warning = FALSE,
	echo=FALSE,
	dpi=300,
	cache=TRUE
	)
```

```{r preliminaries}
library( tidyverse )
library(ggplot2)
library(seqinr)
library(ape)
library(Biostrings)
library(dplyr)
library(plyr)

#clustering
library(cluster)
library(CrossClustering)
library(vegan)
library(Rtsne)
library(factoextra)

#tree manipulation
library(ape)
library(hutan)
```


# What is the distribution of scaffold lengths?   
For each genome, the below code plots a histogram of scaffold lengths and finds the median, maximum, and minimum scaffold lengths.  

The human and zebrafish fastas were too large to run through this code, but median scaffold length was found from online database resources. The many small unplaced scaffolds in the Drosophila toplevel assembly reduced median scaffold length, so only chromosomes were used.   

Note: The below code has been set to run on **sample data**. Unfortunately, the sample data produces weird-looking graphs, but it's not possible to have a full genome in my repo.   

```{r distr scaffold length}


#RUN SAMPLE DATA:
fasta_dir<-"data/sample_data/"
fasta<-c("sample1.fasta")

#RUN REAL DATA:
#fasta_dir<-"~/Desktop/compgen/repo/ensembl/genome_fasta/"
#fasta<-c("Amphimedon_queenslandica.Aqu1.dna.toplevel.fa","Capitella_teleta.Capitella_teleta_v1.0.dna.toplevel.fa","Drosophila_chr.fa", "Helobdella_robusta.Helro1.dna.toplevel.fa","Lottia_gigantea.Lotgi1.dna.toplevel.fa","Mnemiopsis_leidyi.MneLei_Aug2011.dna.toplevel.fa","Nematostella_vectensis.ASM20922v1.dna.toplevel.fa","Strongylocentrotus_purpuratus.Spur_3.1.dna.toplevel.fa","Taeniopygia_guttata.taeGut3.2.4.dna.toplevel.fa","Trichoplax_adhaerens.ASM15027v1.dna.toplevel.fa")

for (blah in fasta){
fasta_path<-paste0(fasta_dir,blah)  

#histogram of all contig lengths,
scaffold.length.plot<-read.fasta(fasta_path)%>%getLength(.)%>%as.data.frame()%>%ggplot()+geom_histogram(aes(x=.), fill="skyblue3", color="black",binwidth=100)+xlab("Scaffold Length (bp)")+ylab("Frequency")+labs(title=blah)
ggsave(scaffold.length.plot,file=paste0("scaffold.len_",blah,".pdf"))

#histogram of contig lengths, restricted to scaffolds < 10,000 bp
restricted.plot<-read.fasta(fasta_path)%>%getLength(.)%>%as.data.frame()%>%filter(.<10000)%>%ggplot()+geom_histogram(aes(x=.), fill="skyblue3", color="black",binwidth=100)+xlab("Scaffold Length (bp)")+ylab("Frequency")+labs(title=blah)
restricted.plot
ggsave(restricted.plot,file=paste0("scaffold.len_10000bp_",blah,".pdf"))

#stats
print(blah)
fasta.len=read.fasta(fasta_path)%>%getLength()
print(paste("Median scaffold/contig length (bp):",median(as.numeric(fasta.len))))
print(paste("Max scaffold/contig length (bp):",max(as.numeric(fasta.len))))
print(paste("Minimum scaffold/contig length (bp):",min(as.numeric(fasta.len))))
  
}

```




# How many scaffolds have at least 3 genes?    
For a given genome, this code plots a frequency histogram of the number of genes per scaffold. For each genome, it also finds the proportion of contigs with at least 3 genes, the median number of genes per contig, and the maximum number of genes per contig. 

Note: The below code has been set to run on **sample data**.   

```{r count no genes per contig/scaffold}

#install.packages("ape")

#RUN SAMPLE DATA:
gff3_dir<-"data/sample_data/"
gff3<-"gff3_sample.gff3"

#RUN REAL DATA:
#gff3_dir<-"data/genomes/gff3/"
#gff3<-c("Amphimedon_queenslandica.Aqu1.42.gff3","Capitella_teleta.Capitella_teleta_v1.0.42.gff3","Danio_rerio.GRCz11.96.chr.gff3","Drosophila_melanogaster.BDGP6.22.96.chr.gff3","Helobdella_robusta.Helro1.42.gff3","Homo_sapiens.GRCh38.96.chr.gff3","Lottia_gigantea.Lotgi1.42.gff3","Mnemiopsis_leidyi.MneLei_Aug2011.42.gff3","Nematostella_vectensis.ASM20922v1.42.gff3","Strongylocentrotus_purpuratus.Spur_3.1.42.gff3","Taeniopygia_guttata.taeGut3.2.4.96.chr.gff3","Trichoplax_adhaerens.ASM15027v1.42.gff3")

for (blah in gff3){


gff3_path<-paste0(gff3_dir,blah)
contig.gene.df <- ape::read.gff(file=gff3_path, GFF3=TRUE) %>% select(.,"seqid","type","start","end") %>% filter(.,type == "gene")

#for histogram, take just the contig names and gene counts
gene.count<- as.data.frame(table(contig.gene.df$seqid))

#plot frequency of frequencies
gff3.plot<-ggplot(data = gene.count, aes(x=gene.count$Freq)) + geom_histogram(binwidth=1) + geom_vline(xintercept = 3,color="red")+ggtitle(blah) +xlab("Number of Genes Per Contig")+ylab("Frequency")+labs(title=blah)
gff3.plot
ggsave(gff3.plot,file=paste0("gff3_",blah,".pdf"))

#use for custom axes
gff3.plot.custom.axes<-ggplot(data = gene.count, aes(x=gene.count$Freq)) + geom_histogram(binwidth=1) + geom_vline(xintercept = 3,color="red") +xlim(0,10)+ylim(0,3000)+xlab("Number of Genes Per Contig")+ylab("Frequency")+labs(title=blah)
gff3.plot.custom.axes
ggsave(gff3.plot.custom.axes,file=paste0("gff3_customaxes_",blah,".pdf"))


#stats
print(blah)
print(paste("proportion contigs with gene count >= 3:",nrow(subset(gene.count, gene.count$Freq >= 3))/nrow(gene.count)*100))
print(paste("Median no. genes/contig:",median(gene.count$Freq)))
print(paste("Max no. genes/contig:",max(gene.count$Freq))) 

}


```


# Prep sequences for Agalma - Select longest peptide only  
## Simplify sequence names  
Download genome protein sequences from Ensembl. 

Agalma cuts off sequence names after the first space. In addition to this, some genomes possess gene, peptide and transcript IDs that don't follow a simple pattern (i.e. cannot "translate" a peptide ID into its transcript ID - the names are seemingly random).

Simplify sequence names while retaining information on the scaffold, gene, transcript and peptide IDs. I used the following format:   
`>p:protID:s:scaffoldID:g:geneID:t:transID`  

To simpify, use Regex "Find":  
Amphimedon:  
>`>(.*?)@pep@scaffold:Aqu1:(Contig\w+):\w+?:\w+?:.*?@gene:(.*?)@transcript:(.*)@gene_biotyp.*`  

Capitella:  
>`>(.*?)@pep@supercontig:Capitella_teleta_v1.0:(CAPTEscaffold_\w+?):\w+?:\w+?:.*?@gene:(.*?)@transcript:(.*?)@.*?$`  

Danio:    
>`>(.*?)@pep@chromosome:GRCz11:(\w+):\w+?:\w+?:.*?@gene:(.*?)@transcript:(.*)@gene_biotype.*`  

Drosophila:    
>`>(.*?)@pep@chromosome:BDGP6:(\w+):\w+?:\w+?:.*?@gene:(.*?)@transcript:(.*)@gene_biotyp.* `  
  
Helobdella:  
>`>(.*?)@pep@supercontig:Helro1:(\w+):\w+?:\w+?:.*?@gene:(.*?)@transcript:(.*)@gene_biotyp.*`  

Homo:   
-need chromosome version AND scaffold version    
>`>(.*?)@pep@scaffold:GRCh38:(.*):\w+?:\w+?:.*?@gene:(.*?)@transcript:(.*)@gene_biotyp.*`    
`>(.*?)@pep@chromosome:GRCh38:(.*):\w+?:\w+?:.*?@gene:(.*?)@transcript:(.*)@gene_biotyp.*`   
 
Danio:    
>`>(.*?)@pep@chromosome:GRCz11:(\w+):\w+?:\w+?:.*?@gene:(.*?)@transcript:(.*)@gene_biotyp.*`    
`>(.*?)@pep@scaffold:GRCz11:(.*):\w+?:\w+?:.*?@gene:(.*?)@transcript:(.*)@gene_biotyp.*`    

Lottia:  
>`>(.*?)@pep@supercontig:Lotgi1:(.*):\w+?:\w+?:.*?@gene:(.*?)@transcript:(.*)@gene_biotyp.*`  
  
Mnemiopsis:     
>`>(.*?)@pep@supercontig:MneLei_Aug2011:(.*):\w+?:\w+?:.*?@gene:(.*?)@transcript:(.*)@gene_biotyp.*`    
`>(.*?)@pep@chromosome:MneLei_Aug2011:(.*):\w+?:\w+?:.*?@gene:(.*?)@transcript:(.*)@gene_biotyp.*`      
Nematostella:  
>`>(.*?)@pep@supercontig:ASM20922v1:(.*):\w+?:\w+?:.*?@gene:(.*?)@transcript:(.*)@gene_biotyp.*`    

Strongylocentrotus:    
>`>(.*?)@pep@supercontig:Spur_3.1:(.*):\w+?:\w+?:.*?@gene:(.*?)@transcript:(.*)@gene_biotyp.*`    

Taeniopygia:  
>`>(.*?)@pep@chromosome:taeGut3.2.4:(.*):\w+?:\w+?:.*?@gene:(.*?)@transcript:(.*)@gene_biotyp.*`    

Trichoplax:  
>`>(.*?)@pep@scaffold:ASM15027v1:(.*):\w+?:\w+?:.*?@gene:(.*?)@transcript:(.*)@gene_biotyp.*`  


Then, Replace with `>p:\1:s:\2:g:\3:t:\4`.  


## Select the longest peptide only  
### Create a list of the longest sequences  
Create a fasta where each gene has only 1 peptide sequence. Choose the longest peptide per gene. The below script produces a single column list of fasta headers of the longest peptide per gene.  

**IMPORTANT NOTE**: Apr28: just noticed a bug. The group_by() doesn't work correctly if you also load the plyr library.  

```{r longest pep only}
#install bioconductor 3.8 https://www.bioconductor.org/install/  
#install Biostrings: BiocManager::install("Biostrings", version = "3.8") ; do not update mclust because it will have a warning and then biostrings module not installed.  

#~~~~~ Beginning of 'story''s code.~~~~~

## read your fasta in as Biostrings object
fasta.s <- readDNAStringSet("./data/sample_data/longest_pep_sample.fasta")

## get the read names (in your case it has the isoform info)
names.fasta <- names(fasta.s)

## extract only the relevant gene and isoform (JM: aka pep) id (split name by the period symbol)
#JM: modify line to fit my name format
gene.iso <- sapply(names.fasta,function(j) cbind(unlist(strsplit(j,'\\:'))[1:8]))

## convert to good data.frame = transpose result from previous step and add relevant column names
gene.iso.df <- data.frame(t(gene.iso))
#JM: alter to put your own column names in:
colnames(gene.iso.df) <- c('p','pepID','s','scaffID','g','geneID','t','transID')
gene.iso.df<-select(gene.iso.df, geneID, pepID)

## and length of isoforms
gene.iso.df$width <- width(fasta.s)

#Did not use rest of code.

#~~~~~ End of 'story''s code.~~~~~

#JM:
gene.iso.df<-rownames_to_column(gene.iso.df)

#~~~~~beginning of code by nassimhddd (Jul 18 '16) Stackoverflow~~~~~
longest.pep.df <-gene.iso.df%>%dplyr::group_by(geneID)%>%mutate(the_rank = rank(-width,ties.method="random")) %>%filter(the_rank==1)%>%select(-the_rank)
#~~~~~End of nassimhddd's code.~~~~~

list<-longest.pep.df[,1,drop=FALSE]
write.csv(list,"longestpep.txt",quote=FALSE,row.names=FALSE)
``` 

### Pull out the longest sequences from a fasta file with fasta_puller.py  
 
To pull out the longest sequences from your fasta file, use fasta_puller.py. This script can be found in the `code` folder. This is the only Python script in the project ;).  

Fasta_puller.py requires that the names in the list exactly match the names in the fasta (including the '>'). This means that you have to Regex the names in the list. I have some sample data for this.  

`code/fasta_puller.py data/sample_data/longestpep_list_sample.txt data/sample_data/fasta_puller_sample.fasta > fasta_puller_output.fasta`  

```
#! /usr/bin/env python
import sys
import re

#def
identity = 0.0
Namefile = []
keep = False

#pull out sequences from a fasta file by name
#usage: fasta_puller.py <listofseqnames> <fastafile.fasta>  
#seq names should be listed in a single column and must exactly match fasta headers.

#open the file with list of sequence names 
#put each name into the list Namefile
File = sys.argv[1]
File = open(File, 'rU')
for Line in File:
	Line = Line.strip('\n')
	Namefile.append(Line)
File.close()

#open the transcriptome file from which sequences are to be pulled from
#since names must match exactly, if you have >TR_blah_blah|cblah_gblah_iblah as name only must alter fastsa names to match 

File = sys.argv[2]
File = open(File, 'rU')
for Line in File:
	Line = Line.strip('\n')
	
	if Line[0]==">":				#for name lines
		keep = False
		for Name in Namefile:
			if Name == Line:
				print Name
				keep = True
				#Namefile.remove(Name)	#hash out if working with gene names only, but want to keep multiple isoforms
	if Line[0] != ">":				#for non-name, ATCG lines
		if keep == True:
			print Line

``` 

# Run Agalma  
The scripts for the Agalma runs can be found in their respective folders in the `agalma` folder.  

A single run-through of Agalma consists of three scripts:    
**1. Catalog the fasta files**  
```
#!/bin/bash
#SBATCH --partition=general
#SBATCH --job-name=agalma_catalog_compgen_noNA_nohydra
#SBATCH -c 1
#SBATCH --mem-per-cpu=6G
#SBATCH --time=0-02:00:00
#SBATCH --mail-type=ALL

export AGALMA_DB="./compgen_homologs_nohydra.sqlite"

source activate /gpfs/ysm/project/jlm329/conda_envs/agalma

set -e

agalma catalog insert -p ../pep/Amphimedon_longestpep.fasta -s 'Amphimedon queenslandica' --id 'Aqu_7c2ad7b'
agalma catalog insert -p ../pep/Capitella_longestpep.fasta -s 'Capitella telata' --id 'Cte_aef8c97'
agalma catalog insert -p ../pep/Danio_longestpep.fasta -s 'Danio rerio' --id 'Dre_a1c97d2'
agalma catalog insert -p ../pep/Drosophila_longestpep.fasta -s 'Drosophila melanogaster' --id 'Dme_05eee07'
agalma catalog insert -p ../pep/Helobdella_longestpep.fasta -s 'Helobdella robusta' --id 'Hro_793004c'
agalma catalog insert -p ../pep/Homo_longestpep.fasta -s 'Homo sapiens' --id 'Hsa_f36e9f9'
agalma catalog insert -p ../pep/Lottia_longestpep.fasta -s 'Lottia gigantea' --id 'Lgi_e03f004'
agalma catalog insert -p ../pep/Mnemiopsis_longestpep.fasta -s 'Mnemiopsis leidyi' --id 'Mle_309f7a5'
agalma catalog insert -p ../pep/Nematostella_longestpep.fasta -s 'Nematostella vectensis' --id 'Nve_2427268'
agalma catalog insert -p ../pep/Strongylocentrotus_longestpep.fasta -s 'Strongylocentrotus purpuratus' --id 'Spu_a9c5697'
agalma catalog insert -p ../pep/Taeniopygia_longestpep.fasta -s 'Taeniopygia guttata' --id 'Tgu_290e6b7'
agalma catalog insert -p ../pep/Trichoplax_longestpep.fasta -s 'Trichoplax adhaerens' --id 'Tad_bdc7fb0'
```

**2. Import**
```
#!/bin/bash
#SBATCH --partition=general
#SBATCH --job-name=agalma_import_compgen_nohydra
#SBATCH -c 16
#SBATCH --mem-per-cpu=6G
#SBATCH --time=2-00:00:00
#SBATCH --mail-type=ALL

export AGALMA_DB="./compgen_homologs_nohydra.sqlite"

source activate /gpfs/ysm/project/jlm329/conda_envs/agalma


set -e


export BIOLITE_RESOURCES="threads=16,memory=6G"


agalma import --id Aqu_7c2ad7b --seq_type aa
agalma annotate --id Aqu_7c2ad7b

agalma import --id Cte_aef8c97 --seq_type aa
agalma annotate --id Cte_aef8c97

agalma import --id Dre_a1c97d2 --seq_type aa
agalma annotate --id Dre_a1c97d2

agalma import --id Dme_05eee07 --seq_type aa
agalma annotate --id Dme_05eee07

agalma import --id Hro_793004c --seq_type aa
agalma annotate --id Hro_793004c

agalma import --id Hsa_f36e9f9 --seq_type aa
agalma annotate --id Hsa_f36e9f9

agalma import --id Lgi_e03f004 --seq_type aa
agalma annotate --id Lgi_e03f004

agalma import --id Mle_309f7a5 --seq_type aa
agalma annotate --id Mle_309f7a5

agalma import --id Nve_2427268 --seq_type aa
agalma annotate --id Nve_2427268

agalma import --id Spu_a9c5697 --seq_type aa
agalma annotate --id Spu_a9c5697

agalma import --id Tgu_290e6b7 --seq_type aa
agalma annotate --id Tgu_290e6b7

agalma import --id Tad_bdc7fb0 --seq_type aa
agalma annotate --id Tad_bdc7fb0
```

**3. Homologize, align, and make gene trees**
```
#!/bin/bash
#SBATCH --partition=general
#SBATCH --job-name=agalma_genetrees_compgen_nohydra
#SBATCH -c 16
#SBATCH --mem-per-cpu=6G
#SBATCH --time=6-00:00:00
#SBATCH --mail-type=ALL

# Script must be run from same directory as existing sqlite database
export AGALMA_DB=$(pwd)"/compgen_homologs_nohydra.sqlite"

source activate /gpfs/ysm/project/jlm329/conda_envs/agalma

set -e


export BIOLITE_RESOURCES="threads=16,memory=6G"

ID=CompGen_nohydra

mkdir -p $ID
cd $ID

agalma homologize --id $ID
agalma multalign --id $ID
agalma genetree --id $ID
```
If Agalma fails at any step, delete all files and start fresh (RE-search!). 

# Parse the Agalma output  
The below script can be found in the `code` folder.  

```
SELECT DISTINCT
       homology.id          AS homology_id,
       genes.gene           AS gene,
       models.catalog_id    AS catalog_id,
       models.id            AS id,
       homology_models.homology_id,
       homology_models.model_id,
       sequences.model_id,
       genes.model_id
FROM agalma_homology        AS homology        JOIN
     agalma_homology_models AS homology_models JOIN
     agalma_models          AS models          JOIN
     agalma_genes           AS genes          JOIN
     agalma_sequences       AS sequences
     ON homology.id=homology_models.homology_id AND
        homology_models.model_id=models.id AND
        models.id=sequences.model_id AND
        models.id=genes.model_id
ORDER BY homology.id ASC;
```
To run the database query:
`sqlite3 -csv -header homologs.sqlite < query_homology.sql > homology_results.csv`


## Agalma Output  
A few things will make life easier down the road when parsing the Agalma output.  

Although the simplified fasta header names are useful for downstream analyses, when merging tables the gene names must exactly match those in the gff3 files. Use Regex Find: `(.*,)p:.*?:s:.*?:g:(.*?):t:.*?(,.*)` and Replace: `$1$2$3`.  

Some of the gene names in the peptide files do not match the gene names in the gff3 files - they have an extra decimal point at the end of their names (I think indicating assembly version). This only occurred in Danio, Homo and Taeniopygia. Remove the decimal point wiht Regex Find:    
Danio:    
>`(\d+,ENSDARG.*).\d+(,Dre_.*)`  
>`(.*,ENSDARG\d+)\.(,Dre_.*)` -> seemed to do the trick better - needed two rounds

Homo:  
>`(\d+,ENSG.*?)\.\d+(,Hsa_.*)`  

Taeniopygia:  
>`(\d+,ENSTGUG.*?).\d+(,Tgu_.*)`  

# Parse the GFF3 and Agalma files  
Both parsing the GFF3 files and reading in the Agalma file is done in the same code chunk below.  
*Note*: The GFF3 files arer in `data/genomes/gff3/`. You have to unzip them first!

## Parse GFF3 files   
1. For each GFF3 file, filter so that only lines where type = 'gene' are extracted. It may seem more direct to filter for 'gene_id', but pseudogenes and ncRNA_genes also have a gene_id. For each species, add these lines to a single dataframe.  
2. Grep out the gene_id and create a new column, 'gene'.  
3. From this, create **gff3.table**: select only the 'seqid' (aka scaffold ID), 'start', 'end', and 'gene' columns, and add a new column called 'animal' that indicates the species name for each gene.    


#### Read in Agalma files   
`agalma.homologs<-read.csv("agalma_results.csv",header=TRUE,sep=",")`.   
This results in **agalma.homologs**. 

```{r Parse GFF3 and Agalma data}


#~~~Create GFF3 Table~~~

#set up empty df to rbind to
all.df<-data.frame(matrix(ncol=5,nrow=0))
names<-c("seqid","type","start","end","attributes")
colnames(all.df)<-names

#set up file names to loop through
gff3_dir="data/genomes/gff3/"
gff3=c("Amphimedon_queenslandica.Aqu1.42.gff3","Capitella_teleta.Capitella_teleta_v1.0.42.gff3","Danio_rerio.GRCz11.95.gff3","Drosophila_melanogaster.BDGP6.95.gff3","Helobdella_robusta.Helro1.42.gff3","Homo_sapiens.GRCh38.95.gff3","Lottia_gigantea.Lotgi1.42.gff3","Mnemiopsis_leidyi.MneLei_Aug2011.42.gff3","Nematostella_vectensis.ASM20922v1.42.gff3","Strongylocentrotus_purpuratus.Spur_3.1.42.gff3","Taeniopygia_guttata.taeGut3.2.4.95.gff3","Trichoplax_adhaerens.ASM15027v1.42.gff3")

#read in each gff3 file and extract seqid, type, start, end, attributes. Filter lines by type = gene.
for (blah in gff3)
{
gff3_path<-paste0(gff3_dir,blah)
contig.gene.df <- ape::read.gff(file=gff3_path, GFF3=TRUE) %>% dplyr::select(.,"seqid","type","start","end","attributes") %>% filter(.,type == "gene")
all.df<-bind_rows(all.df,contig.gene.df)
}

#Parse out the gene_id from the attributes 
all.df$gene<-gsub(".*gene_id=(.*?);.*","\\1",all.df$attributes)

#Construct gff3 table
gff3.table<-select(all.df,"seqid","start","end","gene")

#add animal IDs to gff3 table
gff3.table$animal<-c(rep.int("Amphimedon_queenslandica",43615),rep.int("Capitella_telata",32175),rep.int("Danio_rerio",25606),rep.int("Drosophila_melanogaster",13931),rep.int("Helobdella_robusta",23432),rep.int("Homo_sapiens",21492),rep.int("Lottia_gigantea",23349),rep.int("Mnemiopsis_leidyi",16559),rep.int("Nematostella_vectensis",24773),rep.int("Strongylocentrotus_purpuratus",28987),rep.int("Taeniopygia_guttata",17488),rep.int("Trichoplax_adhaerens",11520))

#~~~ GFF3 Table Finished ~~~


#Read in agalma homologs csv
agalma.homologs<-read.csv("agalma/no_hydra_aka_ALL_ANIMALS/compgen_homologs_nohydra_geneNames.csv",header=TRUE,sep=",")



```

# Perform Cluster Analysis and Make Master Table   
The next chunk performs the cluster analysis. At the end of the chunk, the master table is put together.  
*Important Note*: If you want to rerun this chunk again, you'll have to rerun the above chunk first because gff3.table gets overwritten.  

## Cluster Analysis  
For cluster analysis, gff3.table and agalma.homologs will be inner-joined, then scaffold ID and homology ID will be selected to input into the contingency table.  
An inner join is performed for two reasons:   
1. Remove genes in gff3.table that were not assigned a homology_id by Agalma - these NAs do not add useful information for clustering.   
2. There are some human genes in the Agalma output that are missing from the filtered and unfiltered GFF3 files. Remove.

## Cluster Analysis Steps
1. Filter gff3.table by animal. It is not possible to run an analysis using data from all species. Here, we subsample whichever set of animals we want to cluster.  
2. Create **contingency.table**. As written above, inner join gff3.table x agalma.homologs. Scaffold IDs are not unique, so concatenate scaffold IDs to animal IDs. Select only species-scaffold ID and homology_ids.  
3. Create contingency table: column names are homology IDs, row names are species-scaffold IDs. 
* 1 = homology ID present in scaffold, 0 = homology ID absent in scaffold.  
Subsample contingency table 100x100 to allow computation on a laptop.  
4. Create distance matrix using gower. Gower is a widely used algorithm capable of working on a mix of continuous and categorical data. For categorical data, it uses Jaccard Similarty Index.  
5. Cluster.  
* cross-clustering  
* agnes    
* diana   
* kmeans  
6. Visualize clustering with tSNE or a dendrogram.  

## Create Master Table  
The master table is formed by left-joining gff3.table x agalma.homologs. Then, unique scaffold IDs are created by concatenating scaffold IDs to animal IDs. In addition, cluster IDs from the previous step are added.   

Thus, the master table contains all information gathered so far: scaffold ID, start coordinates, end coordinates, gene ID, homology ID, and cluster ID.  

```{r cluster}
#must run previous chunk prior to running this chunk
gff3.table.save<-gff3.table

#***SUBSAMPLE: choose from which animals you want to cluster scaffolds. Not doing so makes computation impossible on a local machine.
filter_target=c("Homo_sapiens","Danio_rerio","Strongylocentrotus_purpuratus")
gff3.table<-filter(gff3.table, animal==filter_target)


#~~~Create contingency.table~~~
#Make scaffold names unique- join seqid and catalog id
contingency.table<-inner_join(gff3.table,agalma.homologs)%>%dplyr::select(.,seqid,homology_id,animal)%>%mutate(species_scaffold=str_c(seqid,animal,sep="_"))%>%dplyr::select(.,species_scaffold,homology_id)
#~~~contingency.table compelte~~~


#Use contingency.table to make the contingency table
contingency<-table(contingency.table$species_scaffold,contingency.table$homology_id)%>%as.matrix()
contingency<-1*(contingency>0)
#***DOWNSAMPLE contingency table for computation on a local machine.
contingency<-contingency[sample(100),sample(100)]


#distance matrix
dist.matrix<-daisy(contingency,metric="gower",stand=FALSE)


#cluster
#cross-cluster
cross.clust<-cc_crossclustering(dist.matrix,out=FALSE)
clust<-cc_get_cluster(cross.clust)
#plot w/ tSNE
#adjust perplexity if get error "perplexity is too large for the number of samples"
tsne_obj<-Rtsne(dist.matrix,is_distance=TRUE,perplexity=1)
tsne_data<-tsne_obj$Y%>%data.frame()%>%setNames(c("X","Y"))%>%mutate(cluster=factor(clust))
tsne_plot<-ggplot(aes(x = X, y = Y), data = tsne_data) + geom_point(aes(color = cluster)) + labs(title="Cross Cluster tSNE")
tsne_plot

#agglomerative
ag<-agnes(dist.matrix,diss=TRUE)
plot(ag,labels=FALSE)

#divisive
di<-diana(dist.matrix)
plot(di,labels=FALSE)

#kmeans
dist.matrix.coerced<-as.matrix(dist.matrix)
fviz_nbclust(dist.matrix.coerced,kmeans,method="wss")

kmean<-kmeans(dist.matrix,2)
kclust<-kmean$cluster
tsne_obj<-Rtsne(dist.matrix,is_distance=TRUE,perplexity=1)
tsne_data<-tsne_obj$Y%>%data.frame()%>%setNames(c("X","Y"))%>%mutate(cluster=factor(kclust))
tsn_plot_k<-ggplot(aes(x = X, y = Y), data = tsne_data) + geom_point(aes(color = cluster))+labs(title="Kmeans tSNE")
tsn_plot_k
#~~~Clustering complete~~~


#~~~Create master.table.~~~

#Put together a scaffold:cluster df
clust.df<-as.data.frame(clust)
colnames(clust.df)<-"cluster_id"
clust.df<-mutate(clust.df,species_scaffold=row.names(contingency))

master.table<-left_join(gff3.table.save,agalma.homologs)%>%select(.,"seqid","start","end","gene","homology_id","catalog_id","animal")%>%mutate(species_scaffold=str_c(seqid,animal,sep="_"))%>%left_join(.,clust.df,by="species_scaffold")%>%select(.,species_scaffold,start,end,gene,homology_id,animal,cluster_id)



```


# Perform Absence Analysis  
I take a phylogenetic approach:    
1. Find all taxa that possess a particular homology_id.   
2. Find the most recent common ancestor of all those taxa.   
3. Find all the tips of the last common ancestor.  
4. Compare which tips do not possess the homology_id. These are candidate cases of gene loss.  

```{r tree}
#initialize
mrca.df<-data.frame()
taxa.list<-NULL


#phylogeny
tree_text = "(Mnemiopsis_leidyi,(Amphimedon_queenslandica,(Trichoplax_adhaerens,(Nematostella_vectensis,((Drosophila_melanogaster,(Lottia_gigantea,(Capitella_telata,Helobdella_robusta))),(Strongylocentrotus_purpuratus,(Danio_rerio,(Homo_sapiens,Taeniopygia_guttata))))))));"
phy = read.tree(text=tree_text)
plot(phy)


#create a list of unique homology_ids; do not include NAs
homolog.list<-unique(master.table$homology_id)
homolog.list<-homolog.list[!is.na(homolog.list)]


       
for (h in homolog.list){
#1.Find all taxa that possess a particular homology_id. 
homolog.animals<-master.table%>%filter(.,homology_id == h) %>% select(.,animal)%>%unique()

#2. Find the most recent common ancestor of all those taxa. 
#If homology_id is possessed by only 1 taxon (eg. shared among paralogs), then skip. By default, there is no opportunity for detecting absence.  
if (nrow(homolog.animals) == 1){
  next
}

if (nrow(homolog.animals) > 1){
  mrca <-getMRCA(phy,as.character(homolog.animals$animal))
  bind.df<-cbind(homology_id=h,mrca)
  mrca.df<-rbind(mrca.df,bind.df)
}

}

#Add MRCAs to master.table
new.master.table<-left_join(master.table,mrca.df, by="homology_id")


absent.df<-data.frame(h=integer(0),absent.in.taxa=integer(0))
for (h in mrca.df$homology_id){
#3. Find all the tips of the last common ancestor.  
all.tips<-mrca.df$mrca[mrca.df$homology_id==h]%>%descendants(phy,.)
all.tips<-all.tips[all.tips<=length(phy$tip.label)]

taxa<-new.master.table%>%filter(homology_id==h)%>%select(.,animal)%>%unique()


#first find the node number of all animals that taxa with that homology_id
for (t in taxa$animal){
  find.taxa<-which(phy$tip.label==t)
  taxa.list<-append(taxa.list,find.taxa)
}
#4. Compare which tips do not possess the homology_id.
#Where there are no instances in gene loss absent.in.taxa will equal integer(0). Hence need rbind.fill (not rbind) 
absent.in.taxa<-setdiff(all.tips,taxa.list)
taxa.list<-NULL

#append to table of homology_id + absent taxa
combine.df<-cbind(h,absent.in.taxa)%>%as.data.frame()
absent.df<-rbind.fill(absent.df,combine.df)


}

#prep absent.df dataframe
#remove NAs in 'absent' column - these are homologs not absent in any of the child taxa.
absent.df<-na.omit(absent.df)
names(absent.df)<-c("homology_id","absent")

#Create table of scaffold - gene - homology id - taxa homolog is absent in
absence.results<-left_join(master.table,absent.df,by="homology_id")%>%select(.,species_scaffold,gene,homology_id,absent)%>%na.omit(absent)%>%group_by(homology_id)

write.csv(absence.results,"absence.analysis.results.csv",quote=FALSE,row.names=FALSE)

#Add to master table.  
new.master.table<-left_join(new.master.table,absent.df)
```

# Clustering Troubleshooting  

### Is the contingency matrix underlying the distance matrix too sparse?  
The below code makes a histogram of scaffold occupancy per gene, and also finds the median, mean, minimum and maximum number of scaffolds occupied by a gene in a particular genome.  

**Important Note**: The `Parse GFF3 and Agalma data` chunk and the `cluster` chunk must be run first before this chunk. *Whatever you have set as the contingency table there will be the input for this chunk.*    

```{r contingency stats}
# The `Parse GFF3 and Agalma data` chunk and the `cluster` chunk must be run first before this chunk. *Whatever you have set as the contingency table there will be the input for this chunk.*  

#number of scaffolds
nrow(contingency)
#number of homologs shared across scaffolds
ncol(contingency)
#sums of each column
colsum<-colSums(contingency)
#histogram of number of sacffolds occupied per homolog
hist<-ggplot() + aes(colsum)+geom_histogram(fill="skyblue3",color="black")+xlab("Number of Scaffolds Occupied") + ylab("Count")+ggtitle("Number of Scaffolds Occupied Per Homolog (5taxa)")

#median number of scaffolds occupied
median(colsum)
#average number of sacffolds occupied
mean(colsum)
#min number of scaffolds occupied
min(colsum)
#max number of scaffolds occupied.
max(colsum)
```

# Test the Null Hypothesis  
Create a random contingency matrix with the same dimensions and proportion of 1s and 0s as from your real data.  
Cluster this random matrix using cross-clustering, agnes, diana, and kmeans.  
**IMPORTANT NOTE**: You have to run 
```{r test null model}

#mixing up the columns or rows will not affect overall clustering pattern (i.e. all clustering)
#make a data frame with the same proportion of 1's and 0's in random order
dim(contingency)
n_entries<-ncol(contingency)*nrow(contingency)
proportion_1s<-sum(contingency)/n_entries
proportion_0s<-1-proportion_1s

random.matrix<-c(rep("1",proportion_1s*n_entries),rep("0",proportion_0s*n_entries))%>%sample(.,n_entries)%>%matrix(.,ncol=ncol(contingency),nrow=nrow(contingency))%>%as.data.frame()
rownames(random.matrix)<-row.names(contingency)
colnames(random.matrix)<-colnames(contingency)

#distance matrix
rand.dist.matrix<-daisy(random.matrix,metric="gower",stand=FALSE)

#cross-clustering
rand.cross.clust<-cc_crossclustering(rand.dist.matrix,out=FALSE)
rand.clust<-cc_get_cluster(rand.cross.clust)
rand.tsne_obj<-Rtsne(rand.dist.matrix,is_distance=TRUE,perplexity=1)
rand.tsne_data<-rand.tsne_obj$Y%>%data.frame()%>%setNames(c("X","Y"))%>%mutate(rand.cluster=factor(rand.clust))
rand.tsne_plot<-ggplot(aes(x = X, y = Y), data = rand.tsne_data) + geom_point(aes(color = rand.cluster))
rand.tsne_plot

#agglomerative
rand.ag<-agnes(rand.dist.matrix,diss=TRUE)
plot(rand.ag,labels=FALSE)

#divisive
rand.di<-diana(rand.dist.matrix)
plot(rand.di,labels=FALSE)

#kmeans
rand.dist.matrix.coerced<-as.matrix(rand.dist.matrix)
fviz_nbclust(rand.dist.matrix.coerced,kmeans,method="wss")
rand.kmean<-kmeans(rand.dist.matrix,2)
rand.kclust<-rand.kmean$cluster
rand.tsne_obj<-Rtsne(rand.dist.matrix,is_distance=TRUE,perplexity=1)
rand.tsne_data<-rand.tsne_obj$Y%>%data.frame()%>%setNames(c("X","Y"))%>%mutate(rand.cluster=factor(rand.kclust))
rand.tsne_plot<-ggplot(aes(x = X, y = Y), data = rand.tsne_data) + geom_point(aes(color = rand.cluster))
rand.tsne_plot



```


# Deprecated  
Below is my original code for finding absent genes. It used a 'nesting index' approach, where I assigned taxa successively higher 'nesting indices' the more nested it was in the phylogeny.  

```{r final analysis eval = FALSE}
reference="Homo_sapiens"
comparison="Danio_rerio"
result<-data.frame()

#subset master.table for the reference or comparison animal; remove NAs
analysis.table.reference<-filter(master.table,animal==reference & !is.na(homology_id))
analysis.table.comparison<-filter(master.table,animal==comparison & !is.na(homology_id))


#remove any genes in the analysis.table.reference that are present only in clades that arose after the comparison clade.
#get a list of all unique homology_ids in the analysis table
ref.homolog.list<-unique(analysis.table.reference$homology_id)
#get species_index of comparison animal
comp.species.index<-analysis.table.comparison$species_index[1]
#for each gene in the ref analysis table
for (h in ref.homolog.list){
  #select all the rows of that particular genes for all animals (except your comp animal)
  #for sample data:
  #check<-filter(sample.table, homology_id==h & animal!=comparison)
  check<-filter(master.table, homology_id==h & animal!=comparison)
  
  #check if any of the species indices in the check table have an index <= comparison index
  if( any(check$species_index<=comp.species.index)==FALSE){
    #if so, remove all rows with that gene in the analysis.table.reference
    analysis.table.reference<-filter(analysis.table.reference,homology_id != h)
  }
}
#list of unique scaffold ids in reference
ref.scaffold.list<-unique(analysis.table.reference$species_scaffold)
#for each unique scaffold in the reference table:
for (r in ref.scaffold.list){
  #find cluster id for each scaffold
  reference.table.scaffold<-analysis.table.reference%>%filter(.,species_scaffold==r)
  ref.cluster_id<-unique(reference.table.scaffold$cluster_id)
  
  #find all unique scaffolds in comparison table with that cluster_id
  comp.scaffold<-analysis.table.comparison%>%filter(.,cluster_id==ref.cluster_id)
  comp.scaffold<-unique(comp.scaffold$species_scaffold)
  
  #for each unique scaffold in comparison table w/ cluster_id
  for (c in comp.scaffold){
    #isolate genes from that scaffold and compare to original ref scaffold
   comp.table.scaffold<-analysis.table.comparison%>%filter(.,species_scaffold==c)
   comparison_absent<-anti_join(reference.table.scaffold,comp.table.scaffold,by="homology_id")
   comparison_absent<-mutate(comparison_absent,comp_scaff=c)
   result<-rbind(result,comparison_absent)
  }
  
  }
result
write.csv(result,"result.csv",quote=FALSE,row.names=FALSE)
```




